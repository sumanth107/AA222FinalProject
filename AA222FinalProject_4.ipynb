{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Burgers Equation Identification Using ANN-Adam Optimizer\n",
        "Equation:   $u_{t} + \\lambda_1 uu_{x}-\\lambda_2 u_{xx} = 0$  "
      ],
      "metadata": {
        "id": "zuwGrQaCPMU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#author : $um@nth\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import grad\n",
        "import scipy.io\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import least_squares"
      ],
      "metadata": {
        "id": "6h0MvKikPL-X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XwtN2jTsOvnj"
      },
      "outputs": [],
      "source": [
        "N_u = 2500\n",
        "layers = [2, 25, 25, 25, 25, 25, 25, 25, 25, 1]\n",
        "data = scipy.io.loadmat('burgers_shock.mat') \n",
        "t = data['t'].flatten()[:,None]\n",
        "x = data['x'].flatten()[:,None]\n",
        "Exact = np.real(data['usol']).T\n",
        "X, T = np.meshgrid(x,t)\n",
        "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))                  \n",
        "u_star = Exact.flatten()[:,None]                                                 \n",
        "lb = X_star.min(0)                                                              \n",
        "ub = X_star.max(0)\n",
        "np.random.seed(107)\n",
        "idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
        "\n",
        "X_train = X_star[idx,:]\n",
        "u_train = torch.from_numpy(u_star[idx,:]).float()\n",
        "X = torch.from_numpy(X_train[:,0:1]).requires_grad_(True).float()     \n",
        "T = torch.from_numpy(X_train[:,1:2]).requires_grad_(True).float()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "\n",
        "  def __init__(self, X, T, u_train):\n",
        "    self.x = torch.cat([X, T], axis=1).float()\n",
        "    self.y = u_train\n",
        "    self.len = u_train.shape[0]\n",
        "  \n",
        "  def __getitem__(self, index):    \n",
        "      return self.x[index], self.y[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "      return self.len"
      ],
      "metadata": {
        "id": "1Lb3TU9NTZEl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = Data(X, T, u_train)\n",
        "train_loader = DataLoader(dataset=data_set, batch_size=128)"
      ],
      "metadata": {
        "id": "bm0iFRi-TZCB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "SbABIylDTlHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN(nn.Module):\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    super(ANN, self).__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    for i, j in zip(layers, layers[1:]):\n",
        "      linear = nn.Linear(i, j)\n",
        "      nn.init.xavier_normal_(linear.weight.data, gain = 1.0)\n",
        "      nn.init.zeros_(linear.bias.data)\n",
        "      self.layers.append(linear)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    L = len(self.layers)\n",
        "    for l, transform in enumerate(self.layers):\n",
        "      if l < L-1:\n",
        "        x = torch.tanh(transform(x))\n",
        "      else:\n",
        "        x = transform(x)\n",
        "    return x   "
      ],
      "metadata": {
        "id": "BXXAAFOaTZAH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model = ANN(layers)\n",
        "optimizer = torch.optim.Adam(ann_model.parameters(), lr = 0.0005)"
      ],
      "metadata": {
        "id": "ZnjzwIvETY9s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN_train(model, train_loader, optimizer, X, T):\n",
        "  epochs = 5500\n",
        "  mse = nn.MSELoss()\n",
        "  for epoch in range(epochs):\n",
        "    for x1, y1 in train_loader:\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      yhat = model(x1)\n",
        "      loss1 = mse(yhat, y1)\n",
        "      loss = loss1\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch:', epoch, 'Loss: %.5e' % (loss.item()))\n",
        "  return"
      ],
      "metadata": {
        "id": "QQ0S8RGhTY7d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANN_train(ann_model, train_loader, optimizer, X, T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25vkZSZ0TY5B",
        "outputId": "ec8c3dcc-39a3-4e72-8d59-a47db3049cd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 2.28643e-01\n",
            "Epoch: 100 Loss: 4.80102e-03\n",
            "Epoch: 200 Loss: 6.42995e-04\n",
            "Epoch: 300 Loss: 3.10664e-04\n",
            "Epoch: 400 Loss: 2.18946e-04\n",
            "Epoch: 500 Loss: 3.57881e-04\n",
            "Epoch: 600 Loss: 1.18056e-04\n",
            "Epoch: 700 Loss: 1.15186e-04\n",
            "Epoch: 800 Loss: 1.07899e-04\n",
            "Epoch: 900 Loss: 9.47318e-05\n",
            "Epoch: 1000 Loss: 5.21400e-05\n",
            "Epoch: 1100 Loss: 4.69550e-05\n",
            "Epoch: 1200 Loss: 4.38040e-05\n",
            "Epoch: 1300 Loss: 5.18826e-05\n",
            "Epoch: 1400 Loss: 1.80649e-05\n",
            "Epoch: 1500 Loss: 2.28271e-05\n",
            "Epoch: 1600 Loss: 5.16983e-05\n",
            "Epoch: 1700 Loss: 6.23666e-05\n",
            "Epoch: 1800 Loss: 2.69692e-05\n",
            "Epoch: 1900 Loss: 4.20702e-05\n",
            "Epoch: 2000 Loss: 2.97366e-05\n",
            "Epoch: 2100 Loss: 3.83605e-05\n",
            "Epoch: 2200 Loss: 7.83006e-06\n",
            "Epoch: 2300 Loss: 3.47090e-05\n",
            "Epoch: 2400 Loss: 3.27041e-05\n",
            "Epoch: 2500 Loss: 3.05767e-05\n",
            "Epoch: 2600 Loss: 5.87759e-06\n",
            "Epoch: 2700 Loss: 1.14113e-05\n",
            "Epoch: 2800 Loss: 6.74329e-06\n",
            "Epoch: 2900 Loss: 2.85318e-06\n",
            "Epoch: 3000 Loss: 4.19800e-05\n",
            "Epoch: 3100 Loss: 3.99287e-06\n",
            "Epoch: 3200 Loss: 3.34585e-06\n",
            "Epoch: 3300 Loss: 3.38949e-06\n",
            "Epoch: 3400 Loss: 3.91093e-06\n",
            "Epoch: 3500 Loss: 4.76642e-06\n",
            "Epoch: 3600 Loss: 1.78314e-06\n",
            "Epoch: 3700 Loss: 2.46312e-06\n",
            "Epoch: 3800 Loss: 4.59907e-06\n",
            "Epoch: 3900 Loss: 1.17369e-05\n",
            "Epoch: 4000 Loss: 4.09872e-06\n",
            "Epoch: 4100 Loss: 5.37955e-06\n",
            "Epoch: 4200 Loss: 4.75882e-06\n",
            "Epoch: 4300 Loss: 3.87406e-06\n",
            "Epoch: 4400 Loss: 5.00633e-06\n",
            "Epoch: 4500 Loss: 4.68337e-06\n",
            "Epoch: 4600 Loss: 4.81139e-06\n",
            "Epoch: 4700 Loss: 1.34497e-05\n",
            "Epoch: 4800 Loss: 4.92931e-06\n",
            "Epoch: 4900 Loss: 7.11514e-06\n",
            "Epoch: 5000 Loss: 3.03442e-06\n",
            "Epoch: 5100 Loss: 7.61474e-06\n",
            "Epoch: 5200 Loss: 1.16029e-05\n",
            "Epoch: 5300 Loss: 2.33681e-05\n",
            "Epoch: 5400 Loss: 2.12665e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onjy_Sr7YrAe",
        "outputId": "07fa3b73-81c0-4cbf-cafd-6775f7ff1c0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ANN(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=25, bias=True)\n",
              "    (1-7): 7 x Linear(in_features=25, out_features=25, bias=True)\n",
              "    (8): Linear(in_features=25, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_ = torch.from_numpy(X_star[:,0:1]).requires_grad_(True).float()     \n",
        "T_ = torch.from_numpy(X_star[:,1:2]).requires_grad_(True).float()\n",
        "xf = torch.cat([X_, T_], axis=1)\n",
        "uf = ann_model(xf)\n",
        "u_x = grad(uf.sum(), X_, retain_graph = True, create_graph = True)[0]\n",
        "u_xx = grad(u_x.sum(), X_, retain_graph = True, create_graph = True)[0]\n",
        "u_t = grad(uf.sum(), T_, retain_graph = True, create_graph = True)[0]"
      ],
      "metadata": {
        "id": "c91__PCNYq6e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = abs(uf.detach().numpy()-u_star).reshape(-1).argsort()[:150]"
      ],
      "metadata": {
        "id": "NqvZ9tGduaGy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.hstack([(-uf*u_x).detach().numpy(), u_xx.detach().numpy()])\n",
        "B = u_t.detach().numpy()\n",
        "\n",
        "l_1, l_2 = np.linalg.lstsq(A[ind], B[ind], rcond=None)[0]"
      ],
      "metadata": {
        "id": "p17-2lmxt6aA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Lambda1 Pred:', round(l_1[0],8), '  ; Lambda1 Actual:', 1.0)\n",
        "print('Lambda2 Pred:', round(l_2[0],8), '  ; Lambda2 Actual:', round(0.01/np.pi,8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYnmaDZBt6Wl",
        "outputId": "de74a073-5f20-4f5f-e621-e802b2be3f53"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambda1 Pred: 0.7976258   ; Lambda1 Actual: 1.0\n",
            "Lambda2 Pred: 0.00069169   ; Lambda2 Actual: 0.0031831\n"
          ]
        }
      ]
    }
  ]
}